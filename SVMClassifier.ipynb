{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 사용하는 함수, 라이브러리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from scipy.io import wavfile\n",
    "import librosa\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from joblib import dump\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#raw파일을 wav로 변환해주는 함수\n",
    "def raw_to_wav(file_path, sample_rate, directory, filename):\n",
    "    raw_file_path = file_path\n",
    "    raw_data = np.fromfile(raw_file_path, dtype=np.int16)\n",
    "    raw_data_mono = np.mean(raw_data.reshape(-1, 2), axis=1, dtype=np.int16)\n",
    "    output_file = os.path.join(directory, filename) + '.wav'\n",
    "    wavfile.write(output_file, sample_rate, raw_data_mono)\n",
    "    \n",
    "#mfcc 추출하는 함수\n",
    "def extract_mfcc(wav_file):\n",
    "    audio, sr = librosa.load(wav_file)\n",
    "    target_length = 7 * sr  #audio의 길이 패딩해서 맞춤\n",
    "    audio_fixed = np.pad(audio, (0, target_length - len(audio))).astype(np.float32)\n",
    "    mfcc = librosa.feature.mfcc(y=audio_fixed, sr=sr, n_mfcc=39)\n",
    "    return mfcc\n",
    "\n",
    "#raw파일을 wav로 변환해주는 함수 (TestSet용)\n",
    "def test_raw_to_wav(file_path, sample_rate, filename):\n",
    "    raw_file_path = file_path\n",
    "    raw_data = np.fromfile(raw_file_path, dtype=np.int16)\n",
    "    raw_data_mono = np.mean(raw_data.reshape(-1, 2), axis=1, dtype=np.int16)\n",
    "    output_file = os.path.join(filename) + '.wav'\n",
    "    wavfile.write(output_file, sample_rate, raw_data_mono)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 시작\n",
    "##### fmcc_train의 파일명들을 읽어옴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FCJY0/FCJY0_pbw1001\n"
     ]
    }
   ],
   "source": [
    "with open('fmcc_train.ctl', 'r') as file:\n",
    "    file_contents = file.read()\n",
    "files = file_contents.split('\\n')\n",
    "files = files[:-1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 작업공간 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hanja\\ML_Project\n",
      "c:\\Users\\hanja\\ML_Project\\raw16k\\train\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())\n",
    "os.chdir('./raw16k')\n",
    "os.chdir('./train')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### raw 파일 wav 형식으로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "fullpath = [0 for i in range(10000)] #전체 파일 경로 배열\n",
    "directory = [0 for i in range(10000)] #train 데이터 폴더 이름 배열\n",
    "file_name = [0 for i in range(10000)] #train 데이터 파일 이름 배열\n",
    "\n",
    "for i in range(10000):\n",
    "    directory[i], file_name[i] = files[i].split('/')\n",
    "    fullpath[i] = os.path.join(os.getcwd(), directory[i], file_name[i])\n",
    "    fullpath[i] = fullpath[i] + '.raw'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(files)):\n",
    "    raw_to_wav(fullpath[i], 16000, directory[i], file_name[i])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 학습 과정에서의 Test\n",
    "##### TrainSet에서 20%를 검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfccs = [0 for i in range(10000)]\n",
    "\n",
    "for i in range(10000):\n",
    "    mfccs[i] = extract_mfcc(os.path.join(directory[i], file_name[i]) + '.wav') #mfcc 추출"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### 모든 화자 데이터의 앞 80% 학습, 뒤 20% 테스트로 나누면 훈련이 안되는 인물이 있기 때문에 \n",
    "###### 1인당 개별 음성 200개 중 160개 학습, 40개 테스트로 나눔"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "female_mfcc = mfccs[0:5000]\n",
    "male_mfcc = mfccs[5000:10000]\n",
    "i = 0 \n",
    "female_train = []\n",
    "female_test = []\n",
    "male_train = []\n",
    "male_test = []\n",
    "while (i <= 9800):\n",
    "    if (i <= 4800):\n",
    "        female_train += female_mfcc[i:i+160]\n",
    "        female_test += female_mfcc[i+160:i+200]\n",
    "    else:\n",
    "        male_train += male_mfcc[i-5000:i-4840]\n",
    "        male_test += male_mfcc[i-4840:i-4800]\n",
    "    i += 200\n",
    "trainset_data = female_train + male_train\n",
    "testset_data = female_test + male_test\n",
    "trainset_label = np.concatenate((np.zeros(4000), np.ones(4000)))\n",
    "testset_label = np.concatenate((np.zeros(1000), np.ones(1000)))\n",
    "\n",
    "trainset_data = np.array(trainset_data)\n",
    "testset_data = np.array(testset_data)\n",
    "\n",
    "trainset_data = trainset_data.reshape(trainset_data.shape[0], -1)\n",
    "testset_data = testset_data.reshape(testset_data.shape[0], -1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 정확도 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "정확도:  0.9475\n"
     ]
    }
   ],
   "source": [
    "svm_model = make_pipeline(StandardScaler(), SVC()) #standardscaler, svc 통합 모델\n",
    "svm_model.fit(trainset_data, trainset_label)\n",
    "prediction = svm_model.predict(testset_data)\n",
    "accuracy = accuracy_score(testset_label, prediction)\n",
    "print(\"정확도: \", accuracy)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TestSet으로 검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hanja\\ML_Project\n",
      "c:\\Users\\hanja\\ML_Project\\raw16k\n",
      "c:\\Users\\hanja\\ML_Project\\raw16k\\test\n"
     ]
    }
   ],
   "source": [
    "os.chdir(\"../\")\n",
    "os.chdir(\"../\")\n",
    "\n",
    "with open('fmcc_test900.ctl', 'r') as file:\n",
    "    file_contents = file.read()\n",
    "testFiles = file_contents.split('\\n')\n",
    "testFiles = testFiles[:-1]\n",
    "\n",
    "print(os.getcwd())\n",
    "os.chdir(\"./raw16k\") #raw16k 폴더로 이동\n",
    "print(os.getcwd())\n",
    "os.chdir(\"./test\")\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = [0 for i in range(900)] #전체 파일 경로 배열\n",
    "\n",
    "for i in range(900):\n",
    "    path[i] = os.path.join(os.getcwd(), testFiles[i])\n",
    "    path[i] = path[i] + '.raw'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(testFiles)):\n",
    "    test_raw_to_wav(path[i], 16000, testFiles[i])\n",
    "#1~200, 301~500 여성, 501~1000 남성 (201~300 제외)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### TestSet의 Mfcc 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "TestMfccs = [0 for i in range(900)]\n",
    "\n",
    "for i in range(900):\n",
    "    TestMfccs[i] = extract_mfcc(os.path.join(testFiles[i]) + '.wav')\n",
    "\n",
    "Test_data = TestMfccs\n",
    "Test_label = np.concatenate((np.zeros(400), np.ones(500)))\n",
    "\n",
    "Test_data = np.array(Test_data)\n",
    "Test_data = Test_data.reshape(Test_data.shape[0], -1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 기존 모델에 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트셋 정확도:  0.9444444444444444\n"
     ]
    }
   ],
   "source": [
    "predict = svm_model.predict(Test_data)\n",
    "Accuracy = accuracy_score(Test_label, predict)\n",
    "print(\"테스트셋 정확도: \", Accuracy)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 방금 실행된 테스트의 예측값을 바탕으로 테스트 결과 txt파일 작성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../')\n",
    "os.chdir('../')\n",
    "\n",
    "with open('MM_test_results.txt', 'w') as file:\n",
    "    for i in range(len(predict)):\n",
    "        if (predict[i] == 0):\n",
    "            file.write('%s %s\\n' % (testFiles[i], 'feml'))\n",
    "        elif (predict[i] == 1):\n",
    "            file.write('%s %s\\n' % (testFiles[i], 'male'))\n",
    "file.close()\n",
    "\n",
    "os.chdir('./raw16k')\n",
    "os.chdir('./test')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 학습과정의 손실 시각화\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### cpu 사용량을 최대로 하는 교차검증, 폴드 수 = 2 (최소 교차 검증)\n",
    "##### 1회당 추가되는 데이터는 500개 -> 총 20번 검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = 250\n",
    "# train_data = female_mfcc[:a] + male_mfcc[:a]\n",
    "# train_data = np.array(train_data)\n",
    "# train_data = train_data.reshape(train_data.shape[0],-1)\n",
    "# train_label = np.concatenate((np.zeros(a), np.ones(a)))\n",
    "\n",
    "# losses = [0 for i in range(20)]\n",
    "\n",
    "# for i in range(20):\n",
    "#     scores = cross_val_score(svm_model, train_data, train_label, cv=2, scoring='accuracy', n_jobs=-1)\n",
    "#     losses[i] = 1 - scores\n",
    "#     a += 250\n",
    "#     train_data = female_mfcc[:a] + male_mfcc[:a]\n",
    "#     train_data = np.array(train_data)\n",
    "#     train_data = train_data.reshape(train_data.shape[0],-1)\n",
    "#     train_label = np.concatenate((np.zeros(a), np.ones(a)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean = [0 for i in range(20)]\n",
    "# for i in range(len(mean)):\n",
    "#     mean[i] = (losses[i][0] + losses[i][1]) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(np.arange(500, 10001, 500), mean)\n",
    "# plt.xlabel('Number of datas')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.xlim([1500, 10000])\n",
    "# plt.ylim([0.075, 0.27])\n",
    "# plt.title('Loss Curve')\n",
    "# plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
